@online{whitehousecovid2020,
  author = {The White House Office of Science and Technology Policy},
  title = {Call to Action to the Tech Community on New Machine Readable COVID-19 Dataset},
  year = {2020},
  url = {https://www.whitehouse.gov/briefings-statements/call-action-tech-community-new-machine-readable-covid-19-dataset},
  urldate = {2020-16-03}
}

@article{radford2019language,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}

@article{turc2019,
  title={Well-Read Students Learn Better: On the Importance of Pre-training Compact Models},
  author={Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1908.08962v2 },
  year={2019}
}

@article{btz682,
  author = {Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
  title = "{BioBERT: a pre-trained biomedical language representation model for biomedical text mining}",
  journal = {Bioinformatics},
  year = {2019},
  month = {09},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btz682},
  url = {https://doi.org/10.1093/bioinformatics/btz682},
}

@article{use,
  author = {Daniel Cer and Yinfei Yang and Sheng-yi Kong and Nan Hua and Nicole Limtiaco and Rhomni St. John and Noah Constant and Mario Guajardo-Cespedes and Steve Yuan and Chris Tar and Yun-Hsuan Sung and Brian Strope and Ray Kurzweil},
  title = {Universal Sentence Encoder},
  year = {2018},
  eprint = {arXiv:1803.11175},
}

@online{cord19,
  title = {COVID-19 Open Research Dataset (CORD-19)},
  year = {2020},
  url = {https://pages.semanticscholar.org/coronavirus-research},
  urldate = {2020-16-03}
}
